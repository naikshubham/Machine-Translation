{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding one-hot vectors\n",
    "- Keras `to_categorical()` function to create one-hot vectors. The to_categorical() function expects a sequence of integers as the input. Therefore, a word2index dictionary is provided which can be used to convert a word to an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of words and convert them to indices\n",
    "word2index = {\"I\":0, \"like\":1, \"cats\":2}\n",
    "words = [\"I\", \"like\", \"cats\"]\n",
    "word_ids = [word2index[w] for w in words]\n",
    "print(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Create onehot vectors using to_categorical function\n",
    "onehot_1 = to_categorical(word_ids)\n",
    "print(onehot_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', [1.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0]), ('cats', [0.0, 0.0, 1.0])]\n"
     ]
    }
   ],
   "source": [
    "# Print words and their corresponding onehot vectors\n",
    "print([(w,ohe.tolist()) for w,ohe in zip(words, onehot_1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', [1.0, 0.0, 0.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0, 0.0, 0.0]), ('cats', [0.0, 0.0, 1.0, 0.0, 0.0])]\n"
     ]
    }
   ],
   "source": [
    "# Create onehot vectors with a fixed number of classes and print the result\n",
    "onehot_2 = to_categorical(word_ids,num_classes=5)\n",
    "\n",
    "print([(w,ohe.tolist()) for w,ohe in zip(words, onehot_2)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In real-world problems, the vocabulary size can grow very large (e.g. more than hundred thousand) so its important to set `num_classes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def compute_onehot_length(words, word2index):\n",
    "    \"\"\"compute_onehot_length() that generates one-hot vectors for a given list of words\n",
    "    and computes the length of those vectors. \"\"\"\n",
    "    # Create word IDs for words\n",
    "    word_ids = [word2index[w] for w in words]\n",
    "    # Convert word IDs to onehot vectors\n",
    "    onehot = to_categorical(word_ids)\n",
    "    # Return the length of a single one-hot vector\n",
    "    return onehot.shape[1]\n",
    "\n",
    "word2index = {\"He\":0, \"drank\": 1, \"milk\": 2}\n",
    "# Compute and print onehot length of a list of words\n",
    "print(compute_onehot_length([\"He\", \"drank\", \"milk\"], word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_1 => 9  and length_2 =>  6\n"
     ]
    }
   ],
   "source": [
    "word2index= {'He': 6,\n",
    "             'I': 0,\n",
    "             'We': 3,\n",
    "             'cats': 2,\n",
    "             'dogs': 5,\n",
    "             'hates': 7,\n",
    "             'like': 4,\n",
    "             'rabbits': 8}\n",
    "\n",
    "words_1 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"He\", \"hates\", \"rabbits\"]\n",
    "# Call compute_onehot_length on words_1\n",
    "length_1 = compute_onehot_length(words_1, word2index)\n",
    "\n",
    "words_2 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"We\", \"like\", \"cats\"]\n",
    "# Call compute_onehot_length on words_2\n",
    "length_2 = compute_onehot_length(words_2, word2index)\n",
    "\n",
    "# Print length_1 and length_2\n",
    "print(\"length_1 =>\", length_1, \" and length_2 => \", length_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep learning models expect one-hot vectors to always have the same length. Leaving `num_classes` argument unchecked can lead to ill-defined inputs and various compilation errors when fed to Keras models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text reversing model - Encoder\n",
    "- Creating a simple text reversing model is a great method to understand the mechanics of encoder decoder models and how they connect.\n",
    "- **Task** : define the words2onehot() helper function. The words2onehot() function should take in a list of words and a dictionary word2index and convert the list of words to an array of one-hot vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', [1.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0]), ('cats', [0.0, 0.0, 1.0])]\n"
     ]
    }
   ],
   "source": [
    "word2index = {'I': 0, 'cats': 2, 'like': 1}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def words2onehot(word_list, word2index):\n",
    "  # Convert words to word IDs\n",
    "  word_ids = [word2index[w] for w in word_list]\n",
    "  # Convert word IDs to onehot vectors and return the onehot array\n",
    "  onehot = to_categorical(word_ids, num_classes=3)\n",
    "  return onehot\n",
    "\n",
    "words = [\"I\", \"like\", \"cats\"]\n",
    "# Convert words to onehot vectors using words2onehot\n",
    "onehot = words2onehot(words, word2index)\n",
    "# Print the result as (<word>, <onehot>) tuples\n",
    "print([(w,ohe.tolist()) for w,ohe in zip(words, onehot)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a helper function that converts words to onehot vectors which will be fed to the encoder function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The encoder feeds on the one-hot vectors produced by the words2onehot() function.\n",
    "- The encoder() function takes in a set of one-hot vectors and converts them to a list of word ids. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# the encoder of a text reversing model.\n",
    "\n",
    "word2index = {'We': 0, 'dogs': 2, 'like': 1}\n",
    "\n",
    "def encoder(onehot):\n",
    "  # Get word IDs from onehot vectors and return the IDs\n",
    "  word_ids = np.argmax(onehot, axis=1)\n",
    "  return word_ids\n",
    "\n",
    "# Define \"We like dogs\" as words\n",
    "words = ['We', 'like', 'dogs']\n",
    "# Convert words to onehot vectors using words2onehot\n",
    "onehot = words2onehot(words, word2index)\n",
    "# Get the context vector by using the encoder function\n",
    "context = encoder(onehot)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  implement the decoder part of the text reversing model, which will convert the context vector from the encoder to reversed words. \n",
    "- **Task** : defining two functions onehot2words() and decoder(). The onehot2words() function takes in a list of ids and a dictionary index2word and converts an array of one-hot vectors to a list of words. The decoder() function takes in the context vector (i.e., list of word ids) and converts it to the reversed list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogs', 'like', 'We']\n"
     ]
    }
   ],
   "source": [
    "index2word = {0: 'We', 1: 'like', 2: 'dogs'}\n",
    "\n",
    "# Define the onehot2words function that returns words for a set of onehot vectors\n",
    "def onehot2words(onehot, index2word):\n",
    "  ids = np.argmax(onehot, axis=1)\n",
    "  res = [index2word[id] for id in ids]\n",
    "  return res\n",
    "# Define the decoder function that returns reversed onehot vectors\n",
    "def decoder(context_vector):\n",
    "  word_ids_rev = context_vector[::-1]\n",
    "  onehot_rev = to_categorical(word_ids_rev, num_classes=3)\n",
    "  return onehot_rev\n",
    "# Convert context to reversed onehot vectors using decoder\n",
    "onehot_rev = decoder(context)\n",
    "# Get the reversed words using the onehot2words function\n",
    "reversed_words = onehot2words(onehot_rev, index2word)\n",
    "print(reversed_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
